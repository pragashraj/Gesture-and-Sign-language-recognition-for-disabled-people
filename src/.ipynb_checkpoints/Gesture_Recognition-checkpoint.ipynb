{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425d8056",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a26a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tkinter import NW, Tk, Canvas, PhotoImage, Button, Frame, Label\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff017ecb",
   "metadata": {},
   "source": [
    "# 2. Defining & Initializing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ec0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "num_frames = 0\n",
    "\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 400\n",
    "ROI_left = 630"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23cfe7",
   "metadata": {},
   "source": [
    "# 3. Load model for gesture recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d968a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Pragashraj\\Documents\\Gesture and Sign language recognition for disabled people\\src\\model\\Gesture_Model.h5\"\n",
    "model = keras.models.load_model(path)\n",
    "\n",
    "word_dict = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I', 9:'J'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb0309",
   "metadata": {},
   "source": [
    "# 4. Calculate accumulate weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c01e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "\n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "\n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a30010",
   "metadata": {},
   "source": [
    "# 5. Segment the hand from gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d385390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hand(frame, threshold=25):\n",
    "    global background\n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "    _ , thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        return (thresholded, hand_segment_max_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6a8b7",
   "metadata": {},
   "source": [
    "# 6. Convert image to photoImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883445a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "    data = f'P6 {w} {h} 255 '.encode() + img[..., ::-1].tobytes()\n",
    "    return PhotoImage(width=w, height=h, data=data, format='PPM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c387af",
   "metadata": {},
   "source": [
    "# 7. Create text in canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9bd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_text_canvas(message):\n",
    "    text_canvas.delete(\"all\")\n",
    "    text_canvas.create_text(320, 20, text=message, fill=\"#000\", font=('Helvetica 15 bold'))\n",
    "    text_canvas.pack(side=\"bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02076eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_panel_canvas(message):\n",
    "    panel_canvas.create_text(320, 50, text=message, fill=\"#000\", font=('Helvetica 15 bold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff50cc6",
   "metadata": {},
   "source": [
    "# 8. Image resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ba59250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo_image(image):\n",
    "    cv2image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    resized_image= img.resize((640,200), Image.ANTIALIAS)\n",
    "    imgtk = ImageTk.PhotoImage(image = resized_image)\n",
    "    return imgtk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802406b",
   "metadata": {},
   "source": [
    "# 9. Gesture recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6cb604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.title(\"Gesture & Sign Recognition\")\n",
    "root.geometry(\"640x500\")\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "imagePath = r'..\\\\assets\\\\begin.jpg'\n",
    "\n",
    "def update():\n",
    "    global num_frames, ROI_top, ROI_bottom, ROI_right, ROI_left\n",
    "    ret, img = cam.read()\n",
    "    if ret:\n",
    "        frame = cv2.flip(img, 1)\n",
    "        frame_copy = frame.copy()\n",
    "        roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "        gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "        photo = photo_image(frame)\n",
    "        panel_canvas.create_image(0, 0, image=photo, anchor=NW)\n",
    "        panel_canvas.image = photo\n",
    "        panel_canvas.pack(side=\"top\")\n",
    "    if num_frames < 60:\n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        if num_frames <= 59:      \n",
    "            set_text_canvas(\"FETCHING BACKGROUND...PLEASE WAIT\")\n",
    "    else:\n",
    "        hand = segment_hand(gray_frame)\n",
    "        set_text_canvas(\"ADJUST YOUR HAND FOR GESTURE RECOGNITION\")\n",
    "        if hand is not None:\n",
    "            thresholded, hand_segment = hand\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right, ROI_top)], -1, (255, 0, 0),1)\n",
    "            cv2.imshow(\"Thesholded Hand Image\", thresholded)\n",
    "            thresholded = cv2.resize(thresholded, (64, 64))\n",
    "            thresholded = cv2.cvtColor(thresholded, cv2.COLOR_GRAY2RGB)\n",
    "            thresholded = np.reshape(thresholded, (1, thresholded.shape[0], thresholded.shape[1],3))\n",
    "            pred = model.predict(thresholded)\n",
    "            set_panel_canvas(\"GESTURE \" + word_dict[np.argmax(pred)])\n",
    "        else:\n",
    "            set_text_canvas(\"NO HAND DETECTED\")\n",
    "    panel_canvas.create_rectangle(ROI_left, ROI_top, ROI_right, ROI_bottom, outline='blue', width = 2)\n",
    "    num_frames += 1\n",
    "    root.after(10, update)\n",
    "\n",
    "def close():\n",
    "    root.destroy()\n",
    "    \n",
    "panelFrame = Frame(root)\n",
    "panelFrame.pack(side=\"top\")\n",
    "panelFrame.configure(bg=\"white\", width=640, height=400)\n",
    "\n",
    "panel_canvas = Canvas(panelFrame, width=640, height=350)\n",
    "panel_canvas.pack(side=\"top\")\n",
    "\n",
    "text_canvas = Canvas(panelFrame, width=640, height=50)\n",
    "text_canvas.pack(side=\"bottom\", pady=10)\n",
    "\n",
    "set_panel_canvas(\"GESTURE RECOGNITION\")\n",
    "\n",
    "gestureImage = cv2.imread(imagePath)\n",
    "imgtk = get_photo_image(gestureImage)\n",
    "panel_canvas.create_image(0, 100, image=imgtk, anchor=NW)\n",
    "panel_canvas.image = imgtk\n",
    "\n",
    "frame = Frame(root, width=640, height=100)\n",
    "frame.pack(side=\"bottom\")\n",
    "\n",
    "cancel = Button(frame, text=\"CANCEL\", command=close, bg = \"#C0392B\", relief = \"groove\", fg = \"#fff\", bd = 0, width = 20, font=('Helvetica 10 bold'))\n",
    "cancel.pack(side=\"left\",fill=\"both\", expand=\"no\", padx=\"10\", pady=\"10\")\n",
    "\n",
    "start = Button(frame, text=\"START\", command=update, bg = \"#76D7C4\", relief = \"groove\", fg = \"#fff\", bd = 0, width = 80, font=('Helvetica 10 bold'))\n",
    "start.pack(side=\"right\", fill=\"both\", expand=\"no\", padx=\"10\", pady=\"10\")\n",
    "\n",
    "root.mainloop()\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
